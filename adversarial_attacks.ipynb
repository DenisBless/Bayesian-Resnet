{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import math\n",
    "import torchvision.transforms as transforms\n",
    "import torch\n",
    "import torch.utils.data as data\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets\n",
    "from tqdm import tqdm\n",
    "from utils_BNN_resnet import neg_ELBO, Logger\n",
    "from BayesianResnet import resnet18\n",
    "import torchvision.models as models\n",
    "from model_BNN_test import Small_conv_net\n",
    "import torch.nn.functional as F\n",
    "from model_SNN import Net\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "\n",
    "learning_rate = 0.001\n",
    "weight_decay = 0\n",
    "batch_size = 16\n",
    "num_epochs = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert data to a normalized torch.FloatTensor\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261))\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# choose the training and test datasets\n",
    "train_data = datasets.CIFAR10('data', train=True,\n",
    "                              download=True, transform=transform)\n",
    "test_data = datasets.CIFAR10('data', train=False,\n",
    "                             download=True, transform=transform)\n",
    "\n",
    "# prepare data loaders (combine dataset and sampler)\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=16)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Frequentist Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if (use_cuda and torch.cuda.is_available()) else \"cpu\")\n",
    "# Initialize the network\n",
    "model = Net().to(device)\n",
    "\n",
    "criterion=nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 3125/3125 [00:32<00:00, 98.17it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 625/625 [00:01<00:00, 549.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------\n",
      "Epoch: 1\n",
      "--------------------------------------------------------------\n",
      "Trainig loss: 1.5094007669067382\n",
      "--------------------------------------------------------------\n",
      "Accuracy of the network on the train images: 46.004 percent (23002/50000)\n",
      "--------------------------------------------------------------\n",
      "Accuracy of the network on the test images: 45.28 percent (283/625)\n",
      "--------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 3125/3125 [00:32<00:00, 97.62it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 625/625 [00:01<00:00, 543.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------\n",
      "Epoch: 2\n",
      "--------------------------------------------------------------\n",
      "Trainig loss: 1.2709720345878601\n",
      "--------------------------------------------------------------\n",
      "Accuracy of the network on the train images: 54.872 percent (27436/50000)\n",
      "--------------------------------------------------------------\n",
      "Accuracy of the network on the test images: 51.2 percent (320/625)\n",
      "--------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 3125/3125 [00:32<00:00, 95.96it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 625/625 [00:01<00:00, 517.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------\n",
      "Epoch: 3\n",
      "--------------------------------------------------------------\n",
      "Trainig loss: 1.1757421857738495\n",
      "--------------------------------------------------------------\n",
      "Accuracy of the network on the train images: 58.438 percent (29219/50000)\n",
      "--------------------------------------------------------------\n",
      "Accuracy of the network on the test images: 56.32 percent (352/625)\n",
      "--------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 3125/3125 [00:33<00:00, 92.84it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 625/625 [00:01<00:00, 527.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------\n",
      "Epoch: 4\n",
      "--------------------------------------------------------------\n",
      "Trainig loss: 1.1102157763576508\n",
      "--------------------------------------------------------------\n",
      "Accuracy of the network on the train images: 60.906 percent (30453/50000)\n",
      "--------------------------------------------------------------\n",
      "Accuracy of the network on the test images: 60.48 percent (378/625)\n",
      "--------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 3125/3125 [00:33<00:00, 93.64it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 625/625 [00:01<00:00, 537.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------\n",
      "Epoch: 5\n",
      "--------------------------------------------------------------\n",
      "Trainig loss: 1.0577446926307679\n",
      "--------------------------------------------------------------\n",
      "Accuracy of the network on the train images: 62.814 percent (31407/50000)\n",
      "--------------------------------------------------------------\n",
      "Accuracy of the network on the test images: 62.72 percent (392/625)\n",
      "--------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 3125/3125 [00:31<00:00, 98.54it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 625/625 [00:01<00:00, 563.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------\n",
      "Epoch: 6\n",
      "--------------------------------------------------------------\n",
      "Trainig loss: 1.0121273076534272\n",
      "--------------------------------------------------------------\n",
      "Accuracy of the network on the train images: 64.448 percent (32224/50000)\n",
      "--------------------------------------------------------------\n",
      "Accuracy of the network on the test images: 63.2 percent (395/625)\n",
      "--------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 3125/3125 [00:33<00:00, 93.31it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 625/625 [00:01<00:00, 497.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------\n",
      "Epoch: 7\n",
      "--------------------------------------------------------------\n",
      "Trainig loss: 0.9715715975666046\n",
      "--------------------------------------------------------------\n",
      "Accuracy of the network on the train images: 65.986 percent (32993/50000)\n",
      "--------------------------------------------------------------\n",
      "Accuracy of the network on the test images: 65.12 percent (407/625)\n",
      "--------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "frequentist_train_acc = []\n",
    "frequentist_val_acc = []\n",
    "\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    # keep track of training and validation loss\n",
    "    train_loss = 0.0\n",
    "    valid_loss = 0.0\n",
    "\n",
    "    m_train = math.ceil(len(train_data) / batch_size)\n",
    "    m_test= math.ceil(len(test_data) / batch_size)\n",
    "\n",
    "    total = 0\n",
    "    correct = 0\n",
    "\n",
    "    for batch_idx, (data, target) in zip(tqdm(range(m_train)),(train_loader)):\n",
    "        model.train()\n",
    "        # move tensors to GPU if CUDA is available\n",
    "        if use_cuda:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "        optimizer.zero_grad()\n",
    "        # forward pass: compute predicted outputs by passing inputs to the model\n",
    "        output = model(data)\n",
    "\n",
    "        _, predicted = torch.max(output.data, 1)\n",
    "        total += target.size(0)\n",
    "        correct += (predicted == target).sum().item()\n",
    "\n",
    "        # calculate the batch loss\n",
    "        loss = criterion(output, target)\n",
    "        # backward pass: compute gradient of the loss with respect to model parameters\n",
    "        loss.backward()\n",
    "        # perform a single optimization step (parameter update)\n",
    "        optimizer.step()\n",
    "        # update training loss\n",
    "        train_loss += (loss.item() * data.size(0))\n",
    "\n",
    "    test_correct = 0\n",
    "    test_total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        for i, (test_input, test_target) in zip(tqdm(range(m_test)), test_loader):\n",
    "        # for (test_data, test_target) in test_loader:\n",
    "            test_input, test_target = test_input.cuda(), test_target.cuda()\n",
    "            test_outputs= model(test_input)\n",
    "            _, test_predicted = torch.max(test_outputs.data, 1)\n",
    "            test_total += test_target.size(0)\n",
    "            test_correct += (test_predicted == test_target).sum().item()\n",
    "\n",
    "    train_loss = train_loss / len(train_loader.dataset)\n",
    "\n",
    "    frequentist_train_acc.append(correct / total)\n",
    "    frequentist_val_acc.append(test_correct/ test_total)\n",
    "        \n",
    "    print('--------------------------------------------------------------')\n",
    "    print('Epoch:', epoch)\n",
    "    print('--------------------------------------------------------------')\n",
    "    print('Trainig loss:', train_loss)\n",
    "    print('--------------------------------------------------------------')\n",
    "    print('Accuracy of the network on the train images: {} percent ({}/{})'.format (\n",
    "            100 * correct / total, correct, total))\n",
    "    print('--------------------------------------------------------------')\n",
    "\n",
    "    print('Accuracy of the network on the test images: {} percent ({}/{})'.format (\n",
    "            100 * test_correct/ test_total, test_correct,test_total))\n",
    "    print('--------------------------------------------------------------')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilons = [0, .05, .1, .15, .2, .25, .3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FGSM attack code\n",
    "def fgsm_attack(image, epsilon, data_grad):\n",
    "    # Collect the element-wise sign of the data gradient\n",
    "    sign_data_grad = data_grad.sign()\n",
    "    # Create the perturbed image by adjusting each pixel of the input image\n",
    "    perturbed_image = image + epsilon*sign_data_grad\n",
    "    # Adding clipping to maintain [0,1] range\n",
    "    #perturbed_image = torch.clamp(perturbed_image, 0, 1)\n",
    "    # Return the perturbed image\n",
    "    return perturbed_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test( model, device, test_loader, epsilon ):\n",
    "    model.eval()\n",
    "    # Accuracy counter\n",
    "    correct = 0\n",
    "    adv_examples = []\n",
    "\n",
    "    # Loop over all examples in test set\n",
    "    for data, target in test_loader:\n",
    "\n",
    "        # Send the data and label to the device\n",
    "        data, target = data.to(device), target.to(device)\n",
    "\n",
    "        # Set requires_grad attribute of tensor. Important for Attack\n",
    "        data.requires_grad = True\n",
    "\n",
    "        # Forward pass the data through the model\n",
    "        output = model(data)\n",
    "        init_pred = output.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "        # If the initial prediction is wrong, dont bother attacking, just move on\n",
    "        if init_pred.item() != target.item():\n",
    "            continue\n",
    "\n",
    "        # Calculate the loss\n",
    "        loss = F.nll_loss(output, target)\n",
    "\n",
    "        # Zero all existing gradients\n",
    "        model.zero_grad()\n",
    "\n",
    "        # Calculate gradients of model in backward pass\n",
    "        loss.backward()\n",
    "\n",
    "        # Collect datagrad\n",
    "        data_grad = data.grad.data\n",
    "\n",
    "        # Call FGSM Attack\n",
    "        perturbed_data = fgsm_attack(data, epsilon, data_grad)\n",
    "\n",
    "        # Re-classify the perturbed image\n",
    "        output = model(perturbed_data)\n",
    "\n",
    "        # Check for success\n",
    "        final_pred = output.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "        if final_pred.item() == target.item():\n",
    "            correct += 1\n",
    "            # Special case for saving 0 epsilon examples\n",
    "            if (epsilon == 0) and (len(adv_examples) < 5):\n",
    "                adv_ex = perturbed_data.squeeze().detach().cpu().numpy()\n",
    "                adv_examples.append( (init_pred.item(), final_pred.item(), adv_ex) )\n",
    "        else:\n",
    "            # Save some adv examples for visualization later\n",
    "            if len(adv_examples) < 5:\n",
    "                adv_ex = perturbed_data.squeeze().detach().cpu().numpy()\n",
    "                adv_examples.append( (init_pred.item(), final_pred.item(), adv_ex) )\n",
    "\n",
    "    # Calculate final accuracy for this epsilon\n",
    "    final_acc = correct/float(len(test_loader))\n",
    "    print(\"Epsilon: {}\\tTest Accuracy = {} / {} = {}\".format(epsilon, correct, len(test_loader), final_acc))\n",
    "\n",
    "    # Return the accuracy and an adversarial example\n",
    "    return final_acc, adv_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epsilon: 0\tTest Accuracy = 6452 / 10000 = 0.6452\n",
      "Epsilon: 0.05\tTest Accuracy = 1781 / 10000 = 0.1781\n",
      "Epsilon: 0.1\tTest Accuracy = 372 / 10000 = 0.0372\n",
      "Epsilon: 0.15\tTest Accuracy = 96 / 10000 = 0.0096\n",
      "Epsilon: 0.2\tTest Accuracy = 30 / 10000 = 0.003\n",
      "Epsilon: 0.25\tTest Accuracy = 11 / 10000 = 0.0011\n",
      "Epsilon: 0.3\tTest Accuracy = 16 / 10000 = 0.0016\n"
     ]
    }
   ],
   "source": [
    "accuracies = []\n",
    "examples = []\n",
    "\n",
    "# Run test for each epsilon\n",
    "for eps in epsilons:\n",
    "    acc, ex = test(model, device, test_loader, eps)\n",
    "    accuracies.append(acc)\n",
    "    examples.append(ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(5,5))\n",
    "plt.plot(epsilons, accuracies, \"*-\")\n",
    "plt.yticks(np.arange(0, 1.1, step=0.1))\n",
    "plt.xticks(np.arange(0, .35, step=0.05))\n",
    "plt.title(\"Accuracy vs Epsilon\")\n",
    "plt.xlabel(\"Epsilon\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "denisble",
   "language": "python",
   "name": "denisble"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
