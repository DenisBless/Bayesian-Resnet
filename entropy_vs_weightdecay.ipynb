{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import math\n",
    "import torchvision.transforms as transforms\n",
    "import torch\n",
    "import torch.utils.data as data\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets\n",
    "from tqdm import tqdm\n",
    "from utils_BNN_resnet import neg_ELBO, Logger\n",
    "from BayesianResnet import resnet18\n",
    "import torchvision.models as models\n",
    "from model_BNN_test import CNN_lrt\n",
    "import torch.nn.functional as F\n",
    "from model_SNN import Net\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_entropy(probabilities):\n",
    "    try:\n",
    "        ent = -torch.sum(probabilities.cpu() * np.log(1e-16 + probabilities.cpu()), 1)\n",
    "    except:\n",
    "        ent = -torch.sum(probabilities * np.log(1e-16 + probabilities))\n",
    "\n",
    "    return ent\n",
    "\n",
    "def get_max_entropy(probabilities):\n",
    "    p_uniform = 1.0/probabilities.size(1)\n",
    "    p_uniform_dist = torch.ones(probabilities.size(1))*p_uniform\n",
    "    max_ent = -torch.sum(p_uniform_dist * np.log(1e-16 + p_uniform_dist))\n",
    "    \n",
    "    return max_ent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy_vs_eps( model, device, test_loader, epsilon, num_samples ):\n",
    "    softmax = nn.Softmax(dim=1)\n",
    "    model.eval()\n",
    "    # Accuracy counter\n",
    "    correct = 0\n",
    "    entropy = 0.0\n",
    "\n",
    "    # Loop over all examples in test set\n",
    "    #for data, target in test_loader:\n",
    "    for i, (data, target) in zip(tqdm(range(len(test_loader))),(test_loader)):\n",
    "\n",
    "        # Send the data and label to the device\n",
    "        data, target = data.to(device), target.to(device)\n",
    "\n",
    "        # Set requires_grad attribute of tensor. Important for Attack\n",
    "        data.requires_grad = True\n",
    "\n",
    "        # Forward pass the data through the model\n",
    "        output = model(data)\n",
    "\n",
    "        # Calculate the loss\n",
    "        loss = F.nll_loss(output, target)\n",
    "        \n",
    "\n",
    "        # Zero all existing gradients\n",
    "        model.zero_grad()\n",
    "\n",
    "        # Calculate gradients of model in backward pass\n",
    "        loss.backward()\n",
    "\n",
    "        # Collect datagrad\n",
    "        data_grad = data.grad.data\n",
    "\n",
    "        # Call FGSM Attack\n",
    "        perturbed_data = fgsm_attack(data, epsilon, data_grad)\n",
    "\n",
    "        # Re-classify the perturbed image\n",
    "        entropy_tmp = 0.0\n",
    "        for sample in range(num_samples):\n",
    "            # Forward pass the data through the model\n",
    "            output = model(perturbed_data)\n",
    "            probs = softmax(output.data)\n",
    "            entropy_tmp += get_entropy(probs)\n",
    "        \n",
    "        entropy += entropy_tmp/num_samples\n",
    "\n",
    "\n",
    "    entropy_avg = (entropy/len(test_loader)).item()\n",
    "    max_entropy = get_max_entropy(probs)\n",
    "    print(\"Epsilon: {}\\tEntropy = {}\".format(epsilon, entropy_avg))\n",
    "    \n",
    "    \n",
    "    # Return the accuracy and an adversarial example\n",
    "    return entropy_avg, max_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "learning_rate = 0.001\n",
    "batch_size = 16\n",
    "num_epochs = 80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert data to a normalized torch.FloatTensor\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261))\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose the training and test datasets\n",
    "train_data = datasets.CIFAR10('data', train=True,\n",
    "                              download=True, transform=transform)\n",
    "test_data = datasets.CIFAR10('data', train=False,\n",
    "                             download=True, transform=transform)\n",
    "\n",
    "# prepare data loaders (combine dataset and sampler)\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=16)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Frequentist NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = [1e-5, 1e-4, 1e-3, 1e-2, 1e-1]\n",
    "for weight_decay in reg:\n",
    "    # Initialize the network\n",
    "    model = Net().to(device)\n",
    "\n",
    "    criterion=nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
